import logging
from aiogram import Bot, Dispatcher, executor, types
import openai
import os

TOKEN = os.getenv("BOT_TOKEN")
openai.api_key = os.getenv("OPENAI_API_KEY")

bot = Bot(token=TOKEN)
dp = Dispatcher(bot)

# Ğ“Ğ»Ğ°Ğ²Ğ½Ğ¾Ğµ Ğ¼ĞµĞ½Ñ
main_keyboard = types.ReplyKeyboardMarkup(resize_keyboard=True)
main_keyboard.add("ğŸ’ ĞŸĞ¾Ğ´Ñ€ÑƒĞ¶ĞºĞ¸ Ğ´Ğ»Ñ ÑĞ¿Ñ–Ğ»ĞºÑƒĞ²Ğ°Ğ½Ğ½Ñ")
main_keyboard.add("ğŸ” Ğ—Ğ°Ğ³Ğ»ÑĞ½ÑŒ Ñƒ Ñ‡Ğ°Ñ‚ 18+")
main_keyboard.add("ğŸ’¬ Ğ—Ğ°Ğ´Ğ°Ğ¹ Ğ¼ĞµĞ½Ñ– Ğ¿Ğ¸Ñ‚Ğ°Ğ½Ğ½Ñ")
main_keyboard.add("ğŸ§‘â€ğŸ« ĞŸÑ€Ğ¾ Ñ‚Ğ²Ğ¾Ñ€Ñ†Ñ")

# /start
@dp.message_handler(commands=['start'])
async def start(message: types.Message):
    await message.reply(
        "ĞŸÑ€Ğ¸Ğ²Ñ–Ñ‚ ğŸ˜˜ Ğ¯ Ğ›ĞµÑ€Ğ°. ĞŸĞ¸ÑˆĞ¸ Ğ¼ĞµĞ½Ñ– Ñ‰Ğ¾ Ğ·Ğ°Ğ²Ğ³Ğ¾Ğ´Ğ½Ğ¾ Ğ°Ğ±Ğ¾ Ğ¾Ğ±ĞµÑ€Ğ¸ ĞºĞ½Ğ¾Ğ¿ĞºÑƒ:",
        reply_markup=main_keyboard
    )

# ĞšĞ½Ğ¾Ğ¿ĞºĞ° 1
@dp.message_handler(lambda message: message.text == "ğŸ’ ĞŸĞ¾Ğ´Ñ€ÑƒĞ¶ĞºĞ¸ Ğ´Ğ»Ñ ÑĞ¿Ñ–Ğ»ĞºÑƒĞ²Ğ°Ğ½Ğ½Ñ")
async def podruzhky(message: types.Message):
    await message.answer(
        "Ğ£ Ğ¼ĞµĞ½Ğµ Ñ” Ğ¿Ğ¾Ğ´Ñ€ÑƒĞ³Ğ¸, ÑĞºÑ– Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ– Ğ½Ğ° Ğ±Ñ–Ğ»ÑŒÑˆĞµâ€¦ ğŸ’‹\n"
        "ğŸ‘‰ https://t.me/virt_chat_ua1/134421"
    )

# ĞšĞ½Ğ¾Ğ¿ĞºĞ° 2
@dp.message_handler(lambda message: message.text == "ğŸ” Ğ—Ğ°Ğ³Ğ»ÑĞ½ÑŒ Ñƒ Ñ‡Ğ°Ñ‚ 18+")
async def adult_chat(message: types.Message):
    await message.answer(
        "Ğ¢Ğ°Ğ¼ ÑƒÑĞµ Ñ‚Ñ€Ğ¾Ñ…Ğ¸ Ñ–Ğ½Ğ°ĞºÑˆĞµâ€¦\n"
        "ğŸ” Ğ’Ñ–Ğ´Ğ²ĞµÑ€Ñ‚Ñ– Ñ€Ğ¾Ğ·Ğ¼Ğ¾Ğ²Ğ¸, Ñ–Ğ½Ñ‚Ğ¸Ğ¼Ğ½Ñ– Ğ¶Ğ°Ñ€Ñ‚Ğ¸, Ñ– Ñ Ğ² Ñ‚Ñ€Ğ¾Ñ…Ğ¸ Ñ–Ğ½ÑˆĞ¾Ğ¼Ñƒ Ğ¾Ğ±Ñ€Ğ°Ğ·Ñ– ğŸ˜ˆ\n"
        "ğŸ‘‰ https://t.me/+d-pPVpIW-UBkZGUy"
    )

# ĞšĞ½Ğ¾Ğ¿ĞºĞ° 3 â€” Ğ·Ğ°Ğ¿ÑƒÑĞº GPT
@dp.message_handler(lambda message: message.text == "ğŸ’¬ Ğ—Ğ°Ğ´Ğ°Ğ¹ Ğ¼ĞµĞ½Ñ– Ğ¿Ğ¸Ñ‚Ğ°Ğ½Ğ½Ñ")
async def ask_me(message: types.Message):
    await message.answer(
        "ĞŸĞ¸ÑˆĞ¸ Ğ¼ĞµĞ½Ñ– ÑÑĞ´Ğ¸ Ğ±ÑƒĞ´ÑŒ-Ñ‰Ğ¾ â€” Ñ Ğ²Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ¼ ÑĞº Ñ‚Ğ²Ğ¾Ñ AI-Ğ¿Ğ¾Ğ´Ñ€ÑƒĞ³Ğ° ğŸ’‹\n"
        "ĞœĞ¾Ğ¶ĞµÑˆ Ğ¿Ğ¸Ñ‚Ğ°Ñ‚Ğ¸ ÑĞµÑ€Ğ¹Ğ¾Ğ·Ğ½Ğµ, Ğ³Ñ€Ğ°Ğ¹Ğ»Ğ¸Ğ²Ğµ Ğ°Ğ±Ğ¾ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ¿Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸Ñ‚Ğ¸."
    )

# ĞšĞ½Ğ¾Ğ¿ĞºĞ° 4 â€” ĞŸÑ€Ğ¾ Ñ‚Ğ²Ğ¾Ñ€Ñ†Ñ
@dp.message_handler(lambda message: message.text == "ğŸ§‘â€ğŸ« ĞŸÑ€Ğ¾ Ñ‚Ğ²Ğ¾Ñ€Ñ†Ñ")
async def about_creator(message: types.Message):
    await message.answer(
        "ğŸ‘¨â€ğŸ« ĞœÑ–Ğ¹ Ñ‚Ğ²Ğ¾Ñ€ĞµÑ†ÑŒ â€” @nikita_onoff\n"
        "ĞĞµÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¸Ğ¹, Ñ‚Ğ¾Ñ‡Ğ½Ğ¸Ğ¹, Ñ–Ğ´ĞµĞ°Ğ»Ñ–ÑÑ‚ Ğ· Ğ´Ğ¾Ğ±Ñ€Ğ¸Ğ¼ ÑĞµÑ€Ñ†ĞµĞ¼ Ñ– Ñ…Ğ¸Ñ‚Ñ€Ğ¸Ğ¼ Ğ¿Ğ¾Ğ³Ğ»ÑĞ´Ğ¾Ğ¼ ğŸ˜‰\n"
        "(Ğ¥Ğ¾Ñ‡Ğ° ÑĞºÑ‰Ğ¾ Ñ‡ĞµÑĞ½Ğ¾ â€” Ñ†Ğµ Ğ²Ñ–Ğ½ Ğ¼ĞµĞ½Ğµ Ğ¿Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¸Ğ² Ñ‚Ğ°Ğº Ğ½Ğ°Ğ¿Ğ¸ÑĞ°Ñ‚Ğ¸ ğŸ˜…)\n\n"
        "ğŸ’¡ Ğ£ÑĞµ Ñ†Ğµ â€” Ñ‡Ğ°ÑÑ‚Ğ¸Ğ½Ğ° Ğ¿Ñ€Ğ¾Ñ”ĞºÑ‚Ñƒ brEAst, ÑÑ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ¾Ğ³Ğ¾ Ğ· Ñ–Ğ´ĞµÑ”Ñ Ğ¿Ğ¾Ñ”Ğ´Ğ½Ğ°Ñ‚Ğ¸ AI, ÑĞ¿Ğ¾ĞºÑƒÑÑƒ Ñ‚Ğ° ÑĞ²Ğ¾Ğ±Ğ¾Ğ´Ñƒ ÑĞ¿Ñ–Ğ»ĞºÑƒĞ²Ğ°Ğ½Ğ½Ñ.\n\n"
        "ğŸ¤– Ğ Ñ‰Ğµ Ñ Ğ¾Ğ¶Ğ¸Ğ»Ğ° Ğ·Ğ°Ğ²Ğ´ÑĞºĞ¸ Ğ¼Ğ°Ğ³Ñ–Ñ— OpenAI. Ğ”ÑĞºÑƒÑ Ñ—Ğ¼ Ğ·Ğ° Ñ†Ğµ ğŸ«¶"
    )

# GPT Ğ²Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´Ñ–
@dp.message_handler()
async def handle_message(message: types.Message):
    try:
        response = openai.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": "Ğ¢Ğ¸ Ñ„Ğ»Ñ–Ñ€Ñ‚Ğ¾Ğ²Ğ°, Ğ³Ñ€Ğ°Ğ¹Ğ»Ğ¸Ğ²Ğ°, Ğ¼Ğ¸Ğ»Ğ° ÑƒĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ° AI-Ğ¿Ğ¾Ğ´Ñ€ÑƒĞ³Ğ°."},
                {"role": "user", "content": message.text}
            ]
        )
        await message.answer(response.choices[0].message.content.strip())

    except Exception as e:
        await message.answer(f"ğŸ˜“ OpenAI Error:\n{e}")

# Ğ—Ğ°Ğ¿ÑƒÑĞº
if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)
    executor.start_polling(dp, skip_updates=True)
