import os
import logging
import asyncio
from aiogram import Bot, Dispatcher, types
from aiogram.types import ReplyKeyboardRemove
from aiogram.utils import executor
from openai import AsyncOpenAI

API_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ASSISTANT_ID = os.getenv("ASSISTANT_ID")

logging.basicConfig(level=logging.INFO)
bot = Bot(token=API_TOKEN)
dp = Dispatcher(bot)

client = AsyncOpenAI(api_key=OPENAI_API_KEY)

# ĞÑĞ½Ğ¾Ğ²Ğ½Ğµ Ğ¼ĞµĞ½Ñ
main_menu = types.ReplyKeyboardMarkup(resize_keyboard=True)
main_menu.add("ğŸ’ ĞŸĞ¾Ğ´Ñ€ÑƒĞ¶ĞºĞ¸ Ğ´Ğ»Ñ ÑĞ¿Ñ–Ğ»ĞºÑƒĞ²Ğ°Ğ½Ğ½Ñ")
main_menu.add("ğŸ” Ğ—Ğ°Ğ³Ğ»ÑĞ½ÑŒ Ñƒ Ñ‡Ğ°Ñ‚ 18+")
main_menu.add("ğŸ§‘â€ğŸ« ĞŸÑ€Ğ¾ Ñ‚Ğ²Ğ¾Ñ€Ñ†Ñ")
main_menu.add("ğŸ§  Ğ©Ğ¾ Ñ Ğ²Ğ¼Ñ–Ñ")

@dp.message_handler(commands=["start"])
async def start_cmd(message: types.Message):
    await message.reply(
        "ĞŸĞ¸ÑˆĞ¸ Ğ¼ĞµĞ½Ñ– ÑÑĞ´Ğ¸ Ğ±ÑƒĞ´ÑŒ-Ñ‰Ğ¾ â€” Ñ Ğ²Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ¼ ÑĞº Ñ‚Ğ²Ğ¾Ñ AI-Ğ¿Ğ¾Ğ´Ñ€ÑƒĞ³Ğ° ğŸ’‹\nĞœĞ¾Ğ¶ĞµÑˆ Ğ¿Ğ¸Ñ‚Ğ°Ñ‚Ğ¸ ÑĞµÑ€Ğ¹Ğ¾Ğ·Ğ½Ğµ, Ğ³Ñ€Ğ°Ğ¹Ğ»Ğ¸Ğ²Ğµ Ğ°Ğ±Ğ¾ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ¿Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸Ñ‚Ğ¸.",
        reply_markup=main_menu,
    )

@dp.message_handler(lambda message: message.text == "ğŸ’ ĞŸĞ¾Ğ´Ñ€ÑƒĞ¶ĞºĞ¸ Ğ´Ğ»Ñ ÑĞ¿Ñ–Ğ»ĞºÑƒĞ²Ğ°Ğ½Ğ½Ñ")
async def friends_handler(message: types.Message):
    await message.reply(
        "Ğ£ Ğ¼ĞµĞ½Ğµ Ñ” Ğ¿Ğ¾Ğ´Ñ€ÑƒĞ³Ğ¸, ÑĞºÑ– Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ– Ğ½Ğ° Ğ±Ñ–Ğ»ÑŒÑˆĞµâ€¦\nğŸ’‹ ĞĞ±ĞµÑ€Ğ¸ ÑĞ²Ğ¾Ñ Ğ·Ğ° Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ñ”Ğ¼ â€” Ğ¾ÑÑŒ Ğ½Ğ°Ñˆ ÑĞ¿Ğ¸ÑĞ¾Ğº:\nğŸ‘‰ https://t.me/virt_chat_ua1/134421"
    )

@dp.message_handler(lambda message: message.text == "ğŸ” Ğ—Ğ°Ğ³Ğ»ÑĞ½ÑŒ Ñƒ Ñ‡Ğ°Ñ‚ 18+")
async def group_handler(message: types.Message):
    await message.reply(
        "Ğ¢Ğ°Ğ¼ ÑƒÑĞµ Ñ‚Ñ€Ğ¾Ñ…Ğ¸ Ñ–Ğ½Ğ°ĞºÑˆĞµâ€¦\nğŸ” Ğ’Ñ–Ğ´Ğ²ĞµÑ€Ñ‚Ñ– Ñ€Ğ¾Ğ·Ğ¼Ğ¾Ğ²Ğ¸, Ñ–Ğ½Ñ‚Ğ¸Ğ¼Ğ½Ñ– Ğ¶Ğ°Ñ€Ñ‚Ğ¸, Ñ– Ñ Ğ² Ñ‚Ñ€Ğ¾Ñ…Ğ¸ Ñ–Ğ½ÑˆĞ¾Ğ¼Ñƒ Ğ¾Ğ±Ñ€Ğ°Ğ·Ñ– ğŸ˜ˆ\nğŸ‘‰ https://t.me/+d-pPVpIW-UBkZGUy"
    )

@dp.message_handler(lambda message: message.text == "ğŸ§‘â€ğŸ« ĞŸÑ€Ğ¾ Ñ‚Ğ²Ğ¾Ñ€Ñ†Ñ")
async def creator_handler(message: types.Message):
    await message.reply(
        "ğŸ‘¨â€ğŸ« ĞœÑ–Ğ¹ Ñ‚Ğ²Ğ¾Ñ€ĞµÑ†ÑŒ â€” @nikita_onoff\nĞĞµÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¸Ğ¹, Ñ‚Ğ¾Ñ‡Ğ½Ğ¸Ğ¹, Ñ–Ğ´ĞµĞ°Ğ»Ñ–ÑÑ‚ Ğ· Ğ´Ğ¾Ğ±Ñ€Ğ¸Ğ¼ ÑĞµÑ€Ñ†ĞµĞ¼ Ñ– Ñ…Ğ¸Ñ‚Ñ€Ğ¸Ğ¼ Ğ¿Ğ¾Ğ³Ğ»ÑĞ´Ğ¾Ğ¼ ğŸ˜‰\n(Ğ¥Ğ¾Ñ‡Ğ° ÑĞºÑ‰Ğ¾ Ñ‡ĞµÑĞ½Ğ¾ â€” Ñ†Ğµ Ğ²Ñ–Ğ½ Ğ¼ĞµĞ½Ğµ Ğ¿Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¸Ğ² Ñ‚Ğ°Ğº Ğ½Ğ°Ğ¿Ğ¸ÑĞ°Ñ‚Ğ¸ ğŸ˜…)\n\nğŸ’¡ Ğ£ÑĞµ Ñ†Ğµ â€” Ñ‡Ğ°ÑÑ‚Ğ¸Ğ½Ğ° Ğ¿Ñ€Ğ¾Ñ”ĞºÑ‚Ñƒ brEAst, ÑÑ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ¾Ğ³Ğ¾ Ğ· Ñ–Ğ´ĞµÑ”Ñ Ğ¿Ğ¾Ñ”Ğ´Ğ½Ğ°Ñ‚Ğ¸ AI, ÑĞ¿Ğ¾ĞºÑƒÑÑƒ Ñ‚Ğ° ÑĞ²Ğ¾Ğ±Ğ¾Ğ´Ñƒ ÑĞ¿Ñ–Ğ»ĞºÑƒĞ²Ğ°Ğ½Ğ½Ñ.\n\nğŸ¤– Ğ Ñ‰Ğµ Ñ Ğ¾Ğ¶Ğ¸Ğ»Ğ° Ğ·Ğ°Ğ²Ğ´ÑĞºĞ¸ Ğ¼Ğ°Ğ³Ñ–Ñ— OpenAI. Ğ”ÑĞºÑƒÑ Ñ—Ğ¼ Ğ·Ğ° Ñ†Ğµ ğŸ«¶"
    )

@dp.message_handler(lambda message: message.text == "ğŸ§  Ğ©Ğ¾ Ñ Ğ²Ğ¼Ñ–Ñ")
async def about_handler(message: types.Message):
    await message.reply(
        "Ğ¯ Ğ²Ğ¼Ñ–Ñ:\nâ€” Ğ²Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´Ğ°Ñ‚Ğ¸ Ğ½Ğ° ÑĞºĞ»Ğ°Ğ´Ğ½Ñ– Ğ¿Ğ¸Ñ‚Ğ°Ğ½Ğ½Ñ\nâ€” Ğ´Ğ¾Ğ¿Ğ¾Ğ¼Ğ°Ğ³Ğ°Ñ‚Ğ¸ Ğ· Ñ‚ĞµĞºÑÑ‚Ğ°Ğ¼Ğ¸, Ğ´ÑƒĞ¼ĞºĞ°Ğ¼Ğ¸, Ñ–Ğ´ĞµÑĞ¼Ğ¸\nâ€” Ñ„Ğ»Ñ–Ñ€Ñ‚ÑƒĞ²Ğ°Ñ‚Ğ¸ Ğ½Ñ–Ğ¶Ğ½Ğ¾ Ğ°Ğ±Ğ¾ Ğ· Ğ²Ğ¾Ğ³Ğ½Ğ¸ĞºĞ¾Ğ¼ ğŸ˜‰\nâ€” Ñ– Ñ‰Ğµ Ğ±Ğ°Ğ³Ğ°Ñ‚Ğ¾ Ñ‡Ğ¾Ğ³Ğ¾ â€” Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ½Ğ°Ğ¿Ğ¸ÑˆĞ¸ ğŸ’¬"
    )

@dp.message_handler()
async def chat_with_ai(message: types.Message):
    try:
        thread = await client.beta.threads.create()
        await client.beta.threads.messages.create(
            thread_id=thread.id,
            role="user",
            content=message.text
        )
        run = await client.beta.threads.runs.create(
            thread_id=thread.id,
            assistant_id=ASSISTANT_ID
        )
        while run.status != "completed":
            await asyncio.sleep(1)
            run = await client.beta.threads.runs.retrieve(
                thread_id=thread.id,
                run_id=run.id
            )
        messages = await client.beta.threads.messages.list(thread_id=thread.id)
        response = messages.data[0].content[0].text.value
        await message.reply(response)
    except Exception as e:
        await message.reply(f"âš ï¸ ĞŸĞ¾Ğ¼Ğ¸Ğ»ĞºĞ°: {e}")

if __name__ == "__main__":
    executor.start_polling(dp, skip_updates=True)
